<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  

  
  <title>JimmyYoung&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="基于缓冲层的联合细粒度卷积神经网络在人脸欺骗攻击的运用摘要1.0 介绍$\quad$ 在人类追求智能化的过程当中，生物特征检测是其中最贴近现实的技术之一。从最初的指纹，虹膜识别，到现在非常流行的人脸检测，都是为了让我们的生活更加便捷智能，摆脱传统密码等方式带来的不便。特别是人脸识别，是最近几年突飞猛进的技术之一，它确实很大程度地改变了我们生活。但是，目前它也存在着很大的问题，一些打印的照片，回放视">
<meta property="og:type" content="article">
<meta property="og:title" content="JimmyYoung&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/2018/07/23/he_test/index.html">
<meta property="og:site_name" content="JimmyYoung&#39;s Blog">
<meta property="og:description" content="基于缓冲层的联合细粒度卷积神经网络在人脸欺骗攻击的运用摘要1.0 介绍$\quad$ 在人类追求智能化的过程当中，生物特征检测是其中最贴近现实的技术之一。从最初的指纹，虹膜识别，到现在非常流行的人脸检测，都是为了让我们的生活更加便捷智能，摆脱传统密码等方式带来的不便。特别是人脸识别，是最近几年突飞猛进的技术之一，它确实很大程度地改变了我们生活。但是，目前它也存在着很大的问题，一些打印的照片，回放视">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/0061KkpRgy1fq8ymy5v9gj30y20fxt9k.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/0061KkpRgy1fq8zb8uqjgj30yg0bi0tn.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/0061KkpRly1frany54go2j31hc0q8gsm.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/mw690/0061KkpRgy1fqmizfnsv3j30kw0ibjsq.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/0061KkpRly1frfbdwy316j31hc0q8dm7.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/0061KkpRly1frfbjpiu5qj31hc0q8wl8.jpg">
<meta property="og:updated_time" content="2018-06-04T09:19:52.026Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="JimmyYoung&#39;s Blog">
<meta name="twitter:description" content="基于缓冲层的联合细粒度卷积神经网络在人脸欺骗攻击的运用摘要1.0 介绍$\quad$ 在人类追求智能化的过程当中，生物特征检测是其中最贴近现实的技术之一。从最初的指纹，虹膜识别，到现在非常流行的人脸检测，都是为了让我们的生活更加便捷智能，摆脱传统密码等方式带来的不便。特别是人脸识别，是最近几年突飞猛进的技术之一，它确实很大程度地改变了我们生活。但是，目前它也存在着很大的问题，一些打印的照片，回放视">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/0061KkpRgy1fq8ymy5v9gj30y20fxt9k.jpg">
  
    <link rel="alternate" href="/atom.xml" title="JimmyYoung&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">JimmyYoung&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-he_test" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/23/he_test/" class="article-date">
  <time datetime="2018-07-23T13:50:31.236Z" itemprop="datePublished">2018-07-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="基于缓冲层的联合细粒度卷积神经网络在人脸欺骗攻击的运用"><a href="#基于缓冲层的联合细粒度卷积神经网络在人脸欺骗攻击的运用" class="headerlink" title="基于缓冲层的联合细粒度卷积神经网络在人脸欺骗攻击的运用"></a>基于缓冲层的联合细粒度卷积神经网络在人脸欺骗攻击的运用</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><h2 id="1-0-介绍"><a href="#1-0-介绍" class="headerlink" title="1.0 介绍"></a>1.0 介绍</h2><p>$\quad$ 在人类追求智能化的过程当中，生物特征检测是其中最贴近现实的技术之一。从最初的指纹，虹膜识别，到现在非常流行的人脸检测，都是为了让我们的生活更加便捷智能，摆脱传统密码等方式带来的不便。特别是人脸识别，是最近几年突飞猛进的技术之一，它确实很大程度地改变了我们生活。但是，目前它也存在着很大的问题，一些打印的照片，回放视频等欺骗攻击手段确实能骗过某些人脸识别系统，这也是人脸识别目前没有广泛运用于金融等领域的重要原因之一。</p>
<p>$\quad$ 因此，人脸欺骗攻击的识别问题是阻碍人脸识别相关技术进一步推广的重大阻碍。目前也有很多相关的研究，包括传统的特征工程方法，例如利用纹理、表情【】，也有相当多的一部分是利用不同误差函数的卷积神经网络去做一个端对端的训练和识别【】。当然这些做法能够在单一数据集上面取得不错的成绩【】，但是事实上，在单一数据集训练的模型在其他数据集中测试时，准确率远远没有达到自身测试集的精度，并且单一数据集远远不可能趋近实际运用场景中的所有情况【】。因为不同数据集所在的空间域是完全不同的，因此在单一空间域训练的模型自然在其他空间域就不太有效，所以提高模型的泛化性，让模型能够适应更多的空间域，成了非常值得去突破的问题，因此数据集之间的交叉验证的结果就显得十分重要。关于antispoofing的数据集有很多，包括【】，将来也会越来越多，但是都存在一个问题，因为制作成本的原因，数据样本（训练集和测试集）还是很少，因此统计学意义来讲，测试集的准确率并不能完全表达模型的性能。实际上，在目前很多神经网络识别欺骗攻击的研究中,针对的目标是整个人脸，但是整个人脸中并不是每个部分都能很好地将真人脸和攻击人脸区分开，甚至还能产生负影响。</p>
<p>$\quad$ 针对上述问题，我们首先提出了一种根据眼睛，鼻子，嘴巴三部分的联合卷积神经网络。三个独立且一模一样的网络能够分别将最能区分人脸和攻击的特征提取出来，然后根据这些特征去判断。为了更好的提取三部分的特征，我们用的是经过裁剪的inception-V3结构，因为任务的复杂度不高，所以太深的网络将会付出很大的成本。根据这个模型，我们在各项数据集上实现了非常好的效果。之后，为了进一步提高模型的泛化性能，我们在中间加入一层缓冲层，这一层的目的是将目标数据集的空间域向原始空间域靠近，然后固定住其它层的参数，利用一个创新的误差函数去训练新的数据集，以达到更加泛化的模型，在数据集交叉验证中能有更好的表现。</p>
<h2 id="2-0-之前的工作"><a href="#2-0-之前的工作" class="headerlink" title="2.0 之前的工作"></a>2.0 之前的工作</h2><h3 id="2-1-特征表示"><a href="#2-1-特征表示" class="headerlink" title="2.1 特征表示"></a>2.1 特征表示</h3><p>在很长一段时间里，研究者都是通过手动找到区分真人脸和攻击人脸的特征图来区分，这其中包括基于纹理的方法【】，例如LBP【】,以及后续根据LPB延伸的各种方法【】，还有基于HOG算子的算法等也有关于面部动作来区分的【】，例如眨眼、面部表情、头部摇摆等。这些方法也很容易被视频，cut-picture等破解。还有基于频率、颜色、形状等一系列人工设计的特征工程【】。这些方法有的能够起到一些效果，但是人工设计的特征工程，并不能将表达真人脸和攻击人脸最大区分的特征找到，这些方法也许只是找到完整区分特征空间中不一部分。最新也有些基于DNN的特征工程方法也被提出，效果也很不错。</p>
<h3 id="2-2-分类器"><a href="#2-2-分类器" class="headerlink" title="2.2 分类器"></a>2.2 分类器</h3><p>在完成特征工程的工作之后，自然就是要进行分类。其中，通过判别式去区分特征是最常用的方法，例如SVM方法【】，以及一些延伸的方法。还有一些利用回归的方法【】，例如线性回归，逻辑回归等。而近几年，神经网络也越来越受到重视【】。距离度量方法也是其中一种方法，通过测量与真实样本间的差异来区分。这些分类器只能完成一次训练，如果想要加入新的数据，提高模型泛化能力，必须全部重新训练。</p>
<h3 id="2-3-模型泛化"><a href="#2-3-模型泛化" class="headerlink" title="2.3 模型泛化"></a>2.3 模型泛化</h3><p>最近一部分工作也有关于模型泛化相关的研究【】。例如，利用单一数据集上特征的利用无监督学习。同时也有利用多个已经存在的数据集共同训练模型的方法【】。在数据迭代异常迅速的今天，如果又有新的更全面的数据集，需要重新全部训练，当模型非常巨大的，代价非常高。面对这样的问题，迁移学习提供了一个很好的思路，最近涌现出很多利用CNN的迁移学习相关的研究【】，在共享大部分的网络结构的基础上，能够解决不同空间的转换学习问题，但同时肯定会引起灾难性遗忘。基于此，我们在单个任务中利用了迁移学习的方式实现了单一任务的增量学习，以提高模型的泛化能力，同时能够有效抑制灾难性遗忘。与以往的增量学习不同，大多数要实现N分类到N+m分类的转变【】，我们要关注的是输出不变的情况下，增加学习的目标而不遗忘之前所学习到的知识。</p>
<h3 id="2-4-数据集"><a href="#2-4-数据集" class="headerlink" title="2.4 数据集"></a>2.4 数据集</h3><p>关于人脸欺骗攻击的数据集很多。其中欺骗种类包括：打印照片、裁剪掉眼睛的照片、视频回放以及面具。在这里我们选用CASIA,REPLAY-ATTACK、MSU-MFSD，NUAA四个经典的公开数据集进行测试，不仅是单独测试，还会进行交叉训练和交叉数据集测试。从数据集的组成可以看出，尽管数据集很多，但是单一数据集的数量仍然不够多，没能达到imgnet，coco相关数据集的完备性，所以只关注单一数据集的度量结果是没有意义的，我们更加关注在不同数据集的交叉测试的结果，从这个结果我们能更加看出方法模型的性能。</p>
<h2 id="3-0-方法"><a href="#3-0-方法" class="headerlink" title="3.0 方法"></a>3.0 方法</h2><p>卷积神经网络已经被现实证明，具有强大的图像特征提取能力，从最初的AlexNet，然后inceptionV3，直到最新的DenseNet，在各种计算机视觉的任务中都保持着最高的准确率。我们提出方法的主要思想就是利用卷积网络得到的多部分细粒度特征去识别真人脸和攻击人脸。然后利用缓冲层实现增量学习，增加模型的泛化性能。</p>
<h3 id="3-1-联合细粒度CNN模型"><a href="#3-1-联合细粒度CNN模型" class="headerlink" title="3.1 联合细粒度CNN模型"></a>3.1 联合细粒度CNN模型</h3><p><img src="http://ww1.sinaimg.cn/large/0061KkpRgy1fq8ymy5v9gj30y20fxt9k.jpg"></p>
<ul>
<li><strong>模型</strong>：在人脸相关的研究当中，人脸矫正是必不可少的一部分【】，因为相关研究已经证明，神经网络对于旋转没有等变性【】，所以在将图片输入模型之前，首先利用landmark进行人脸的矫正，这样做的目的是为了避免因为真假人脸因为头部姿势不同导致CNN模型学习特征的偏差。然后分别将人的眼眉部分，鼻子部分，嘴巴部分提取出来，在这里我们没有将三个部分resize成一个大多数CNN网络都会用的正方形size，而是根据面部原来的比例缩放至一个标准的size，以减少三部分特征的遗失；接着将三部分分别输入到一个剪切的inceptionV3网络当中，之所以剪切一部分，最大的原因是提高模型的训练速度，inceptionV3模型在复杂的任务中能够有很好的表现，所以在相对简单的任务中不需要那么深的层数；最后将三部分的特征图联合起来由全连接层进行分类。整个CNN的框架上图所示。</li>
</ul>
<p><img src="http://ww1.sinaimg.cn/large/0061KkpRgy1fq8zb8uqjgj30yg0bi0tn.jpg"></p>
<ul>
<li><strong>LOSS函数</strong>：剪切的CNN如上图。对于每个部分需要进行单独的预训练，三个相同结构的二分类任务能够将最能区分真人脸和攻击人脸的特征提取出来，训练完后，我们将3个1024维向量联合成3096维向量，这个向量就是最终的特征图。从数据集的结构可以看出，数据之间的不均衡性问题很突出，不仅如此，由于很多数据集是视频数据，相邻帧的相似度很高，因此在训练过程中非常容易出现过拟合。为了避免数据不均衡所导致学习的偏向性以及数据重复性带来的过拟合，我们运用了一种新的focal-loss函数【】来取代交叉熵Loss函数,公式如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\mathcal&#123;L&#125; = \frac 1 N \sum^&#123;N&#125; -\alpha(1-p_&#123;t&#125;)^&#123;\gamma&#125;\log(p_&#123;t&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>其中$p_t$定义如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">p_t =  \begin&#123;cases&#125; </span><br><span class="line">   p ,&amp;if \quad y =1\\</span><br><span class="line">    1-p,&amp;otherwise</span><br><span class="line">    \end&#123;cases&#125;</span><br></pre></td></tr></table></figure></p>
<p>上面$y$为标签，$p$标签为1时的概率。通过这个公式可以看出，在训练一个mini-batch的过程中，当某个数据通过现有模型预测的置信度很高，$(1-p_{t})^{\gamma}$这一部分就会降低这个数据在整个batch中的LOSS值，$\gamma$的大小影响降低的程度。之所以有这样的效果，显而易见，因为这一部分是一个单调递减函数。这样就能挑选出整个数据集中缺乏学习的数据进行着重训练，有效缓解了数据不均衡导致的某一类训练过拟合而另一类训练欠拟合的情况。为了调整最后输出loss的取值范围，加入了正则系数$\alpha$。而在实际中，我们只对一个batch的所有loss的前70%的值进行计算，loss太小的不予考虑，只挑选比较难学习的那一部分进行反向传播的参数更新。之前，这两种方法大多用于目标检测，但是对于源数据不均衡的任务同样有效，而且效果显著，在后面的实验会提到。</p>
<ul>
<li><strong>数据增强</strong>：通过观察和实验发现，在测试的数据集中，有些真实人脸的头发对眉眼部分有遮挡，或者是眼镜的反光等，容易误判成攻击人脸，原因之一就是训练集中大多数是男性，头发没有遮挡，而测试集中的光线不可能和训练集一模一样，当测试集出现这些情况，不能有效区分。为了增加模型的鲁棒性，我们对眉眼部分的数据集进行了数据增强。首先将眉眼部分横向分为三部分，然后分别将每一部分的像素值变为0作为一个新数据，然后纵向同样分为三部分，依次将像素变为0作为新数据，我们并没有对每一张图片都进行这样的增强。这样的增强对于模型有很好的效果，后面的实验也会提到。</li>
</ul>
<p>通过上面的方法，我们可以在每个单一数据集上拥有优秀的准确率。但是如果将这个训练好的模型，直接对其他数据集进行测试时，效果会非常不理想。而人脸攻击检测是面向实际运用的研究，实际运用中就会出现各种不同的环境，包括摄像头的不同、光线的不同等，所以如何在不断迭代的数据集中快速有效的利用新的数据集信息，使我们的模型逐渐成长，成了我们要面对的最大困难。</p>
<h3 id="3-2-Buffer层"><a href="#3-2-Buffer层" class="headerlink" title="3.2 Buffer层"></a>3.2 Buffer层</h3><p>目前也有一些方法，也是在模型中间加入一些中间层，有的是为了模型加速，如NET2NET【】；有的是为了做迁移学习，如DDC、DAN【】；但是这些方法关注的是从一个任务到另一个任务的模型迁移。也有一些增量学习方法，最新的研究是FEARNET，但它主要解决的是由一个多分类问题向更多分类问题的转换。而我们要解决的问题在同一个任务上，更好的适应不断更新的数据集，以泛化我们的已有模型，更好解决当前任务，最大化减少时间成本和运算成本。最近也有相关工作关注到了这方面的问题，研究了不同摄像头下的测试效果【】，而我们提出的buffer层就是为了这个目的而来的。如下图：</p>
<p><img src="http://ww1.sinaimg.cn/large/0061KkpRly1frany54go2j31hc0q8gsm.jpg"></p>
<p>绿色和黑色是源域特征图经过PCA转化到三维空间的分布，而黄色和红色是目标域在经过源域训练的模型得到的特征图分布。buffer层的目标就是在不改变源域分布的情况下，将目标域经过buffer层之后向源域靠近。源域的两个分布就像吸铁石一样，分别吸引着目标域的两个分布。</p>
<ul>
<li><strong>模型</strong>：模型如下图：</li>
</ul>
<center> <img src="http://ww1.sinaimg.cn/mw690/0061KkpRgy1fqmizfnsv3j30kw0ibjsq.jpg"> </center>

<p>基本的框架模型和上面的训练模型一模一样，就是在特征生成器和分类器之间加入一个buffer层，在训练的过程中，冻结住其他参数，只训练buffer层。图上面的模型称为判别器D，下面的称为生成器G，在训练过程中，生成器会根据判别器产生一个domain距离，根据这个距离去做domain transfer。最终的LOSS函数分为domain loss 和 label loss两部分。</p>
<ul>
<li><strong>LOSS函数</strong>：在训练的一个mini-batch中，我们分为两个部分，1/2为源域的训练集数据，1/2为目标域训练集数据。为了表达域之间的距离，我们用了MMD距离【】。公式如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">MMD^2[\mathcal&#123;k&#125;,X,Y] = \frac&#123;1&#125;&#123;m(m-1)&#125; \sum_&#123;i \neq j&#125;^m \mathcal&#123;k&#125;(\mathcal&#123;x_i&#125;,\mathcal&#123;x_j&#125;) + \frac&#123;1&#125;&#123;n(n-1)&#125; \sum_&#123;i \neq j&#125;^n \mathcal&#123;k&#125;(\mathcal&#123;y_i&#125;,\mathcal&#123;y_j&#125;) - \frac&#123;2&#125;&#123;mn&#125; \sum_&#123;i,j=1&#125;^&#123;n,m&#125; \mathcal&#123;k&#125;(\mathcal&#123;x_i&#125;,\mathcal&#123;y_j&#125;)</span><br></pre></td></tr></table></figure>
<p>其中，m,n分别表示源域和目标域训练集个数，k表示核函数，在实验中，用的是rbf核函数。</p>
<p>但是单核的MMD距离表征能力有限，我们采用了MK-MMD方式去表征域之间的距离【】。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">\mathcal&#123;K&#125; := \&#123; k:k=\sum_&#123;u=1&#125;^&#123;d&#125; \beta_u k_u,\sum_&#123;u=1&#125;^&#123;d&#125; \beta_u =D,\beta_u \geq0 ,\forall u \in \&#123;1,...,d\&#125;\&#125;</span><br></pre></td></tr></table></figure>
<p>其中 $D&gt;0$ ，每一个 $k \in \mathcal{K}$ 代表了一个特殊的 $RKHS$ 空间 $\mathcal{F}_k$ ,并假定 $ |k_u| \leq K$, $\forall u \in {1,…,d}$。所以 $MMD$ 的表达形式为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">MMD^2[X,Y] = \sum_&#123;u=1&#125;^d \beta_u *MMD^2[\mathcal&#123;k_u&#125;,X,Y]</span><br></pre></td></tr></table></figure>
<p>之前有提到1/2为源域的训练集数据，1/2为目标域训练集数据，是因为我们想要在不改变源域分布特点的情况下，将目标域的分布特点向源域分布的特点靠拢。为了实现这个目标，我提出了一个新的loss函数，增加了一些监督信号：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">\mathcal&#123;L&#125;= \mathcal&#123;L&#125;_&#123;label&#125; + \alpha \mathcal&#123;D&#125;(X_&#123;G&#125;^s,X_&#123;D&#125;^s) + \beta \mathcal&#123;D&#125;(X_&#123;G&#125;^s,X_&#123;D&#125;^t)</span><br></pre></td></tr></table></figure>
<p>其中 $\mathcal{L}<em>{label}$ 就是上文提到的FOCALLOSS，$\alpha ,\beta$是一个调整参数，$\mathcal{D}(X</em>{G}^s,X<em>{D}^s)$表示的是生成器源域和判别器源域之间空间误差，$\mathcal{D}(X</em>{G}^s,X_{D}^t)$表示的是生成器源域和判别器目标域之间空间误差。两者的表示分别如下：</p>
<script type="math/tex; mode=display">
\mathcal{D}(X_{G}^s,X_{D}^s) = MMD^2(X_{G}^{s+},X_{D}^{s+}) + MMD^2(X_{G}^{s-},X_{D}^{s-})</script><script type="math/tex; mode=display">
\mathcal{D}(X_{G}^s,X_{D}^t) = MMD^2(X_{G}^{s+},X_{D}^{t+}) + MMD^2(X_{G}^{s-},X_{D}^{t-})</script><p>其中$X<em>{G}^{+}$、$X</em>{G}^{+}$表示的是相同数据集下的正负样本，因为网络是一个二分类，所以需要将正负样本之间的距离单独计算，已达到源域正负分布的分布像磁铁一样将目标域正负样本的分布拉向目标域。通过这样一个目标loss函数的训练，效果如下图：</p>
<p><img src="http://ww1.sinaimg.cn/large/0061KkpRly1frfbdwy316j31hc0q8dm7.jpg"></p>
<p>黑色和绿色仍然是源域的正负样本分布，相对于没有经过buffer层的分布，黄色红色已经能够明显看出再向源域靠拢，且可分性明显变好。再来看看加入buffer层之后，源域的分布情况：</p>
<p><img src="http://ww1.sinaimg.cn/large/0061KkpRly1frfbjpiu5qj31hc0q8wl8.jpg"></p>
<p>也是基本不变的。所以融合了两个分布的模型的泛化性有了进一步的提高。</p>
<h2 id="4-0-实验"><a href="#4-0-实验" class="headerlink" title="4.0 实验"></a>4.0 实验</h2><h3 id="4-1-数据集"><a href="#4-1-数据集" class="headerlink" title="4.1 数据集"></a>4.1 数据集</h3><p>本文主要利用三个数据集CASIA,REALPLAYATTACK,MSU-MFSD，NUAA。</p>
<p>REALPLAYATTACK包含50个人的1200个视频，攻击类型包括视频攻击和平整打印图像攻击。拍摄的分辨率只有一种类型。</p>
<p>MSU包含35个人的280个视频，攻击类型包括视频攻击和平整打印图像攻击。拍摄包含两种分辨率。</p>
<p>其中CASIA所包含的攻击类型最为全面，包括warped-photo，eye-cut-photo，video-playback三种攻击类型。整个数据集有50个人的视频，其中20个人的视频当做训练集，30个人当做测试集，每个人包含由三种不同分辨率的12个视频。无论从供给手段还是分辨率种类都是十分丰富的，所以我们利用这个数据集当做基准数据集。</p>
<p>NUAA全部是图片数据，由于度量标准的偏差，所我们在实验中把这个数据集当做辅助训练的数据集，以测试模型的泛化性。</p>
<h3 id="4-2-实验度量"><a href="#4-2-实验度量" class="headerlink" title="4.2 实验度量"></a>4.2 实验度量</h3><p>在以前的一些实验中，对单一数据集进行训练，然后直接将模型用在另一个数据集的测试集上判断ERR等指标，本文的方法旨在增加模型的泛化性能，测试方法的有效性，一般的评价方法或者利用数据集的方式不再适用。我们首先利用基准数据集进行训练，接着去测试验证数据集，然后利用联合数据集训练buffer层，然后用这样一个模型去测试同样的验证数据集。这样就可以看出通过一个buffer层能否增加它的泛化性能。度量标准采用ERR，HTER两个指标，对于单个视频文件，我们采用CASIA的判断准则，随机抽取一个视频的30帧，取平均预测值</p>
<h3 id="4-3-实验步骤"><a href="#4-3-实验步骤" class="headerlink" title="4.3 实验步骤"></a>4.3 实验步骤</h3><p>整个实验建立在tensorflow框架上，硬件环境是K80的GPU。在训练过程中，采用动态的学习率-[0.01,0.001,0.0001,0.00001]，mini-batch是128</p>
<h4 id="4-3-1-Ablation-Study"><a href="#4-3-1-Ablation-Study" class="headerlink" title="4.3.1 Ablation Study"></a>4.3.1 Ablation Study</h4><p>首先我们在CASIA数据集上验证本文利用人脸三局部的基准模型的有效性。先用利用整张人脸的数据去进行识别，然后分别去掉眼睛、鼻子、嘴巴三个部分，与建议的方法做对比。这样可以证明在face-antispoofing的任务中，将人脸最具特征的三部分提取出来联合判断的方法有效。为了最大限度的保持原始数据，我们根据人脸正常的五官比例去rezise三个部分。实验结果如下图，</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>model</th>
<th>EER</th>
<th>HTER</th>
</tr>
</thead>
<tbody>
<tr>
<td>face</td>
<td></td>
<td></td>
</tr>
<tr>
<td>face(eye cut)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>face(nose cut)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>face(mouth cut)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>propose method</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>在数据集中，数据非常不均衡，genuine相比于antispoofing的数据非常少，所以在最后的实验结果中的表现是，在antispoofing的测试集上准确率远远比genuine的数据集，也就是说genuine非常容易误判。为此，我们运用在线选取困难样本的focal-loss函数，以减小数据不均衡问题。为达到较好的效果，将 $\gamma$ 设置为2，这样可以弱化简单样本在整个loss中的比重，$\alpha$ 根据loss的输出值，调整为10。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>model</th>
<th>0</th>
<th>1</th>
<th>EER</th>
<th>HTER</th>
</tr>
</thead>
<tbody>
<tr>
<td>model(CE)</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>model(Focal-Loss)</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p>在设计buffer层的时候，我们也考虑buffer设计几层的考虑，过多的buffer layer会导致训练速度成倍数增加，过浅的buffer layer有可能导致无法拟合加入更多监督信号之后的模型，下面是具体的实验结果：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>model</th>
<th>0</th>
<th>1</th>
<th>EER</th>
<th>HTER</th>
</tr>
</thead>
<tbody>
<tr>
<td>model with 1-buffer layer</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>model with 2-buffer layer</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>model with 3-buffer layer</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>model with 4-buffer layer</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h4 id="4-3-2-Intra-Datasets-Testing"><a href="#4-3-2-Intra-Datasets-Testing" class="headerlink" title="4.3.2 Intra Datasets Testing"></a>4.3.2 Intra Datasets Testing</h4><p>我们将我们最好的结果与当前主流以及过去有效方法的结果进行对比，其中包括基于纹理和传统机器学习算法的，也有基于神经网络等方法【】。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Reference</th>
<th>FEATURE</th>
<th>Classifier</th>
<th>HTER/EER</th>
</tr>
</thead>
<tbody>
<tr>
<td>name1</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>name2</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>name3</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>name4</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h4 id="4-3-3-Cross-Datasets-Testing"><a href="#4-3-3-Cross-Datasets-Testing" class="headerlink" title="4.3.3 Cross Datasets Testing"></a>4.3.3 Cross Datasets Testing</h4><p>为了增加模型的泛化性，适应更多的场景，设计出buffer层，通过domain transfer实现增量学习，在不遗忘原有数据集特征的情况下，对新的数据集训练集进行学习，这样就将两个数据集的domain进行融合，用一个模型在两个domain中去区分genuine和antispoofing。</p>
<table>
   <tr>
      <td colspan="2"> train datdastes</td>
      <td>test datasets</td>
      <td>model</td>
      <td>ERR</td>
      <td>HTER</td>
   </tr>
   <tr>
      <td rowspan="12">CASIA</td>
      <td rowspan="12">NUAA</td>
      <td rowspan="4"><center>CASIA</center></td>
      <td>source</td>
      <td>5.6%</td>
      <td>3.9%</td>
   </tr>
   <tr>
      <td>source(with mask)</td>
      <td>4.6%</td>
      <td>8.35%</td>
   </tr>
   <tr>
      <td>buffer</td>
      <td>3.7%</td>
      <td>3.1%</td>
   </tr>
    <tr>
      <td>buffer(with mask)</td>
      <td>4.1%</td>
      <td>3.9%</td>
   </tr>
      <tr>
      <td rowspan="4"><center>MSU</center></td>
      <td>source</td>
      <td>32.5%</td>
      <td>35.8%</td>
   </tr>
   <tr>
      <td>source(with mask)</td>
      <td>30.8%</td>
      <td>33.35%</td>
   </tr>
   <tr>
      <td>buffer</td>
      <td>17.7%</td>
      <td>21.3%</td>
   </tr>
    <tr>
      <td>buffer(with mask)</td>
      <td>20%</td>
      <td>25.4%</td>
   </tr>
      
      
      <tr>
      <td rowspan="4"><center>Replay</center></td>
      <td>source</td>
      <td> 24.5%</td>
      <td> 25%</td>
   </tr>
   <tr>
      <td>source(with mask)</td>
      <td> 29.7%</td>
      <td>  42%</td>
   </tr>
   <tr>
      <td>buffer</td>
      <td> 21.8%</td>
      <td> 16.85%</td>
   </tr>
    <tr>
      <td>buffer(with mask)</td>
      <td>  26.5%</td>
      <td>  27.7%</td>
   </tr>
</table>


<table>
   <tr>
      <td colspan="2"> train datdastes</td>
      <td>test datasets</td>
      <td>model</td>
      <td>ERR</td>
      <td>HTER</td>
   </tr>
   <tr>
      <td rowspan="8">CASIA</td>
      <td rowspan="8">MSU</td>
      <td rowspan="4"><center>CASIA</center></td>
      <td>source</td>
      <td>5.6%</td>
      <td>3.9%</td>
   </tr>
   <tr>
      <td>source(with mask)</td>
      <td>4.6%</td>
      <td>8.35%</td>
   </tr>
   <tr>
      <td>buffer</td>
      <td> %</td>
      <td> %</td>
   </tr>
    <tr>
      <td>buffer(with mask)</td>
      <td> %</td>
      <td> %</td>
   </tr>
      <tr>
      <td rowspan="4"><center>Replay</center></td>
      <td>source</td>
      <td> %</td>
      <td> %</td>
   </tr>
   <tr>
      <td>source(with mask)</td>
      <td> %</td>
      <td> %</td>
   </tr>
   <tr>
      <td>buffer</td>
      <td> %</td>
      <td> %</td>
   </tr>
    <tr>
      <td>buffer(with mask)</td>
      <td> %</td>
      <td> %</td>
   </tr>
</table>




<table>
   <tr>
      <td colspan="2"> train datdastes</td>
      <td>test datasets</td>
      <td>model</td>
      <td>ERR</td>
      <td>HTER</td>
   </tr>
   <tr>
      <td rowspan="8">CASIA</td>
      <td rowspan="8">Replay</td>
      <td rowspan="4"><center>CASIA</center></td>
      <td>source</td>
      <td>5.6%</td>
      <td>3.9%</td>
   </tr>
   <tr>
      <td>source(with mask)</td>
      <td>4.6%</td>
      <td>8.35%</td>
   </tr>
   <tr>
      <td>buffer</td>
      <td> %</td>
      <td> %</td>
   </tr>
    <tr>
      <td>buffer(with mask)</td>
      <td> %</td>
      <td> %</td>
   </tr>
      <tr>
      <td rowspan="4"><center>MSU</center></td>
      <td>source</td>
      <td> %</td>
      <td> %</td>
   </tr>
   <tr>
      <td>source(with mask)</td>
      <td> %</td>
      <td> %</td>
   </tr>
   <tr>
      <td>buffer</td>
      <td> %</td>
      <td> %</td>
   </tr>
    <tr>
      <td>buffer(with mask)</td>
      <td> %</td>
      <td> %</td>
   </tr>
</table>

<h4 id="4-3-3-Visualization-and-Discussion"><a href="#4-3-3-Visualization-and-Discussion" class="headerlink" title="4.3.3 Visualization and Discussion"></a>4.3.3 Visualization and Discussion</h4><p>从上面可以看出，我们所提出的方法很有效地实现了对模型进一步的泛化。因为利用新的监督信号训练buffer层，能够在不改变模型对原有domain的情况下，将新的domain转移到原有domain的空间。如下图：</p>
<p>（数据图表还需要生成）</p>
<p>（用一些图表量化domain之间的距离差距）</p>
<h2 id="5-0-总结"><a href="#5-0-总结" class="headerlink" title="5.0  总结"></a>5.0  总结</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/23/he_test/" data-id="cjjycr5uf0001w4udukfgr5y0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2018/07/23/he/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/07/23/he_test/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/07/23/he/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/07/23/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 JimmyYoung<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>